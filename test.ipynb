{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.8/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/jimx/miniconda3 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/jimx/.mujoco/mujoco210/bin')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# from fastchat.train.llama_flash_attn_monkey_patch import (\n",
    "#     replace_llama_attn_with_flash_attn,\n",
    "# )\n",
    "# replace_llama_attn_with_flash_attn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda-11.8/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/jimx/miniconda3 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/jimx/miniconda3/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/jimx/.mujoco/mujoco210/bin')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "import time\n",
    "import torch\n",
    "\n",
    "model_path = \"/home/jimx/pretrained_models/meta-llama/Llama-2-13b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d76a0aad720477da8440ef9e11f54f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: \"/home/jimx/pretrained_models/meta-llama/Llama-2-13b-hf/model-00001-of-00003.safetensors\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# add loading time:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_path,local_files_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,use_safetensors\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16)\n\u001b[1;32m      4\u001b[0m end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading time: \u001b[39m\u001b[39m\"\u001b[39m, end_time\u001b[39m-\u001b[39mstart_time)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:2903\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2893\u001b[0m     \u001b[39mif\u001b[39;00m dtype_orig \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2894\u001b[0m         torch\u001b[39m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   2896\u001b[0m     (\n\u001b[1;32m   2897\u001b[0m         model,\n\u001b[1;32m   2898\u001b[0m         missing_keys,\n\u001b[1;32m   2899\u001b[0m         unexpected_keys,\n\u001b[1;32m   2900\u001b[0m         mismatched_keys,\n\u001b[1;32m   2901\u001b[0m         offload_index,\n\u001b[1;32m   2902\u001b[0m         error_msgs,\n\u001b[0;32m-> 2903\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_load_pretrained_model(\n\u001b[1;32m   2904\u001b[0m         model,\n\u001b[1;32m   2905\u001b[0m         state_dict,\n\u001b[1;32m   2906\u001b[0m         loaded_state_dict_keys,  \u001b[39m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   2907\u001b[0m         resolved_archive_file,\n\u001b[1;32m   2908\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   2909\u001b[0m         ignore_mismatched_sizes\u001b[39m=\u001b[39;49mignore_mismatched_sizes,\n\u001b[1;32m   2910\u001b[0m         sharded_metadata\u001b[39m=\u001b[39;49msharded_metadata,\n\u001b[1;32m   2911\u001b[0m         _fast_init\u001b[39m=\u001b[39;49m_fast_init,\n\u001b[1;32m   2912\u001b[0m         low_cpu_mem_usage\u001b[39m=\u001b[39;49mlow_cpu_mem_usage,\n\u001b[1;32m   2913\u001b[0m         device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m   2914\u001b[0m         offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m   2915\u001b[0m         offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m   2916\u001b[0m         dtype\u001b[39m=\u001b[39;49mtorch_dtype,\n\u001b[1;32m   2917\u001b[0m         is_quantized\u001b[39m=\u001b[39;49m(load_in_8bit \u001b[39mor\u001b[39;49;00m load_in_4bit),\n\u001b[1;32m   2918\u001b[0m         keep_in_fp32_modules\u001b[39m=\u001b[39;49mkeep_in_fp32_modules,\n\u001b[1;32m   2919\u001b[0m     )\n\u001b[1;32m   2921\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_4bit \u001b[39m=\u001b[39m load_in_4bit\n\u001b[1;32m   2922\u001b[0m model\u001b[39m.\u001b[39mis_loaded_in_8bit \u001b[39m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:3246\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3244\u001b[0m \u001b[39mif\u001b[39;00m shard_file \u001b[39min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3245\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m-> 3246\u001b[0m state_dict \u001b[39m=\u001b[39m load_state_dict(shard_file)\n\u001b[1;32m   3248\u001b[0m \u001b[39m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3249\u001b[0m \u001b[39m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m mismatched_keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3251\u001b[0m     state_dict,\n\u001b[1;32m   3252\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3256\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3257\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:447\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39mReads a PyTorch checkpoint file, returning properly formatted errors if they arise.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_file\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.safetensors\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m is_safetensors_available():\n\u001b[1;32m    446\u001b[0m     \u001b[39m# Check format of the archive\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     \u001b[39mwith\u001b[39;00m safe_open(checkpoint_file, framework\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    448\u001b[0m         metadata \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mmetadata()\n\u001b[1;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m metadata\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mflax\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: \"/home/jimx/pretrained_models/meta-llama/Llama-2-13b-hf/model-00001-of-00003.safetensors\""
     ]
    }
   ],
   "source": [
    "# add loading time:\n",
    "start_time = time.time()\n",
    "model = LlamaForCausalLM.from_pretrained(model_path,local_files_only=True,device_map=\"auto\",use_safetensors=True,torch_dtype=torch.float16)\n",
    "end_time = time.time()\n",
    "print(\"Loading time: \", end_time-start_time)\n",
    "\n",
    "# use_safetensors 13b:14.44\n",
    "# no use_safetensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    # temperature=0.7,\n",
    "    # top_p=0.75,\n",
    "    num_beams=5,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "def evaluate(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].cuda()\n",
    "    start_time = time.time()\n",
    "    generation_output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        generation_config=generation_config,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        max_new_tokens=256\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    print(output)\n",
    "    token_len = tokenizer.tokenize(output)\n",
    "    # print token/second:\n",
    "    print(\"token/second:\",len(token_len) / (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(\"what is the weather in New York?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(instruction, input=None):\n",
    "    if input:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=\"\"\"A Russian naval ship has been damaged in a Ukrainian naval drone attack in the Black Sea, Ukrainian sources say. The assault reportedly occurred near the Russian port of Novorossiysk, which is a major hub for Russian exports. Russia's defence ministry said it had repelled a Ukrainian attack on its naval base there which involved two sea drones, but did not admit any damage. But Ukrainian security service sources say the Olenegorsky Gornyak was hit and suffered a serious breach. They told the BBC a sea drone was carrying 450kg (992lb) of dynamite when it hit the ship. Russia made no mention of any damage in its report of the incident. Sea drones are small, unmanned vessels which operate on or below the water's surface. A video sent to the BBC by a source with Ukraine's security service appears to show the drone approaching a ship thought to be the Olenegorsky Gornyak. The footage shows a vessel travelling right up to the side of a ship before the feed cuts out, apparently on impact. Another unverified video is thought to show the ship listing to one side.\"\"\"\n",
    "x = generate_prompt(\"Please summarize the following text\", inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Please summarize the following text\n",
      "\n",
      "### Input:\n",
      "A Russian naval ship has been damaged in a Ukrainian naval drone attack in the Black Sea, Ukrainian sources say. The assault reportedly occurred near the Russian port of Novorossiysk, which is a major hub for Russian exports. Russia's defence ministry said it had repelled a Ukrainian attack on its naval base there which involved two sea drones, but did not admit any damage. But Ukrainian security service sources say the Olenegorsky Gornyak was hit and suffered a serious breach. They told the BBC a sea drone was carrying 450kg (992lb) of dynamite when it hit the ship. Russia made no mention of any damage in its report of the incident. Sea drones are small, unmanned vessels which operate on or below the water's surface. A video sent to the BBC by a source with Ukraine's security service appears to show the drone approaching a ship thought to be the Olenegorsky Gornyak. The footage shows a vessel travelling right up to the side of a ship before the feed cuts out, apparently on impact. Another unverified video is thought to show the ship listing to one side.\n",
      "\n",
      "### Response:\n",
      "A Russian naval ship has been damaged in a Ukrainian naval drone attack in the Black Sea, Ukrainian sources say. The assault reportedly occurred near the Russian port of Novorossiysk, which is a major hub for Russian exports. Russia's defence ministry said it had repelled a Ukrainian attack on its naval base there which involved two sea drones, but did not admit any damage. But Ukrainian security service sources say the Olenegorsky Gornyak was hit and suffered a serious breach. They told the BBC a sea drone was carrying 450kg (992lb) of dynamite when it hit the ship. Russia made no mention of any damage in its report of the incident. Sea drones are small, unmanned vessels which operate on or below the water's surface. A video sent to the BBC by a source with Ukraine's security service appears to show the drone approaching a ship thought to be the Olenegorsky Gornyak. The footage shows a vessel travelling right up to the side of a ship before the feed cuts out, apparently on impact. Another unverified video is thought to show the ship\n",
      "token/second: 32.32341427385795\n"
     ]
    }
   ],
   "source": [
    "evaluate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
